{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad0453d6",
   "metadata": {},
   "source": [
    "    \"# üå± Plant Disease Detection using CNN\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook demonstrates how to train and use a Convolutional Neural Network for plant disease detection using the New Plant Diseases Dataset from Kaggle.\\n\",\n",
    "    \"\\n\",\n",
    "    \"## üìò Overview\\n\",\n",
    "    \"Plant diseases significantly affect crop yield and food production worldwide. This project uses CNNs to automatically classify healthy and diseased leaves from 38 different classes.\\n\",\n",
    "    \"\\n\",\n",
    "    \"**Dataset**: [New Plant Diseases Dataset](https://www.kaggle.com/datasets/vipoooool/new-plant-diseases-dataset)\\n\",\n",
    "    \"\\n\",\n",
    "    \"## Table of Contents\\n\",\n",
    "    \"1. [Setup and Imports](#setup)\\n\",\n",
    "    \"2. [Data Analysis](#data-analysis)\\n\",\n",
    "    \"3. [Model Training](#model-training)\\n\",\n",
    "    \"4. [Model Evaluation](#model-evaluation)\\n\",\n",
    "    \"5. [Making Predictions](#predictions)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa02712",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports {#setup}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b36044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the src directory to Python path\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Core imports\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Custom modules\n",
    "from model import PlantDiseaseDetector\n",
    "from data_preprocessing import DataPreprocessor\n",
    "from evaluation import ModelEvaluator\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configure matplotlib\n",
    "plt.style.use('default')\n",
    "sns.set_palette('husl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516176c2",
   "metadata": {},
   "source": [
    "## 2. Data Analysis {#data-analysis}\n",
    "\n",
    "Let's start by analyzing our dataset structure and distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a79d456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data preprocessor\n",
    "dataset_path = \"../dataset\"  # Update this path to your dataset location\n",
    "preprocessor = DataPreprocessor(dataset_path)\n",
    "\n",
    "# Analyze dataset structure\n",
    "print(\"üìä Dataset Analysis\")\n",
    "print(\"=\" * 50)\n",
    "class_counts = preprocessor.analyze_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5615486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class distribution\n",
    "if class_counts:\n",
    "    classes = list(class_counts.keys())\n",
    "    counts = list(class_counts.values())\n",
    "    \n",
    "    plt.figure(figsize=(15, 8))\n",
    "    bars = plt.bar(range(len(classes)), counts, color='skyblue', alpha=0.7)\n",
    "    plt.xlabel('Disease Classes')\n",
    "    plt.ylabel('Number of Images')\n",
    "    plt.title('Distribution of Images Across Disease Classes')\n",
    "    plt.xticks(range(len(classes)), [c.replace('___', '\\n') for c in classes], \n",
    "               rotation=45, ha='right')\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, count in zip(bars, counts):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 10,\n",
    "                f'{count}', ha='center', va='bottom', fontsize=8)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nTotal classes: {len(classes)}\")\n",
    "    print(f\"Total images: {sum(counts)}\")\n",
    "    print(f\"Average images per class: {np.mean(counts):.1f}\")\n",
    "    print(f\"Min images in a class: {min(counts)}\")\n",
    "    print(f\"Max images in a class: {max(counts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ec9202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample images from each class\n",
    "print(\"üñºÔ∏è  Sample Images from Dataset\")\n",
    "print(\"=\" * 50)\n",
    "# preprocessor.visualize_sample_images(samples_per_class=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f000d2d",
   "metadata": {},
   "source": [
    "## 3. Model Training {#model-training}\n",
    "\n",
    "Now let's build and train our CNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6a5944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the plant disease detector\n",
    "print(\"ü§ñ Initializing Plant Disease Detector\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "detector = PlantDiseaseDetector(\n",
    "    img_height=224,\n",
    "    img_width=224,\n",
    "    num_classes=38  # Update based on your dataset\n",
    ")\n",
    "\n",
    "# Build the model\n",
    "model = detector.build_model()\n",
    "\n",
    "# Compile the model\n",
    "detector.compile_model(learning_rate=0.001)\n",
    "\n",
    "print(\"Model built and compiled successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3950cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display model architecture\n",
    "print(\"üìã Model Architecture\")\n",
    "print(\"=\" * 50)\n",
    "model.summary()\n",
    "\n",
    "# Plot model architecture\n",
    "tf.keras.utils.plot_model(model, show_shapes=True, show_layer_names=True, \n",
    "                          rankdir='TB', dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b5a01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for training\n",
    "print(\"üìÅ Preparing Training Data\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Note: Update the path to your actual dataset location\n",
    "train_dir = \"../dataset/train\"\n",
    "\n",
    "if os.path.exists(train_dir):\n",
    "    # Prepare datasets\n",
    "    train_ds, val_ds = detector.prepare_data(\n",
    "        train_dir=train_dir,\n",
    "        batch_size=32,\n",
    "        validation_split=0.2\n",
    "    )\n",
    "    \n",
    "    print(f\"Training batches: {len(train_ds)}\")\n",
    "    print(f\"Validation batches: {len(val_ds)}\")\n",
    "    print(f\"Class names: {detector.class_names[:5]}...\")  # Show first 5 classes\n",
    "    \n",
    "    data_ready = True\n",
    "else:\n",
    "    \"‚ö†Ô∏è  Dataset not found! Please download and extract the New Plant Diseases Dataset.\\\")\\n\",\n",
    "    \"    print(\\\"üì• Download from: https://www.kaggle.com/datasets/vipoooool/new-plant-diseases-dataset\\\")\\n\",\n",
    "    \"    print(\\\"üìÅ Extract to: ../dataset/train/\\\")\n",
    "    data_ready = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f40f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model (only if data is available)\n",
    "if 'data_ready' in locals() and data_ready:\n",
    "    print(\"üèãÔ∏è Training the Model\")\n",
    "    print(\"=\" * 50)\n",
    "    print(\"This may take several hours depending on your hardware...\")\n",
    "    \n",
    "    # Train with a small number of epochs for demonstration\n",
    "    # Increase epochs for better performance\n",
    "    history = detector.train(\n",
    "        train_ds=train_ds,\n",
    "        val_ds=val_ds,\n",
    "        epochs=5  # Use 50+ epochs for real training\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Training completed!\")\n",
    "else:\n",
    "    print(\"‚è∏Ô∏è  Skipping training - dataset not available\")\n",
    "    print(\"üìù To train the model:\")\n",
    "    \"   1. Download the New Plant Diseases Dataset\\\")\\n\",\n",
    "    \"    print(\\\"   2. Extract to ../dataset/train/\\\")\n",
    "    print(\"   3. Re-run this cell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db0087a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history (if model was trained)\n",
    "if 'history' in locals():\n",
    "    print(\"üìà Training History\")\n",
    "    print(\"=\" * 50)\n",
    "    detector.plot_training_history(history)\n",
    "    \n",
    "    # Save the trained model\n",
    "    model_path = \"../models/plant_disease_model.h5\"\n",
    "    os.makedirs(\"../models\", exist_ok=True)\n",
    "    detector.save_model(model_path)\n",
    "    print(f\"üíæ Model saved to: {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2a0bfa",
   "metadata": {},
   "source": [
    "## 4. Model Evaluation {#model-evaluation}\n",
    "\n",
    "Let's evaluate our trained model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b607e514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model (if trained)\n",
    "if 'data_ready' in locals() and data_ready and 'history' in locals():\n",
    "    print(\"üìä Model Evaluation\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Initialize evaluator\n",
    "    evaluator = ModelEvaluator(model, detector.class_names)\n",
    "    \n",
    "    # Generate comprehensive evaluation report\n",
    "    metrics = evaluator.generate_evaluation_report(val_ds)\n",
    "    \n",
    "    print(\"\\nüìã Final Metrics Summary:\")\n",
    "    print(f\"Accuracy: {metrics['accuracy']:.4f}\")\n",
    "    print(f\"Precision: {metrics['precision']:.4f}\")\n",
    "    print(f\"Recall: {metrics['recall']:.4f}\")\n",
    "    print(f\"F1-Score: {metrics['f1_score']:.4f}\")\n",
    "    print(f\"Top-5 Accuracy: {metrics['top5_accuracy']:.4f}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚è∏Ô∏è  Skipping evaluation - model not trained\")\n",
    "    print(\"üîÑ Train the model first to see evaluation results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549e8322",
   "metadata": {},
   "source": [
    "## 5. Making Predictions {#predictions}\n",
    "\n",
    "Let's see how to use our trained model for predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be6cbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: How to make predictions with a trained model\n",
    "print(\"üîÆ Making Predictions\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if 'data_ready' in locals() and data_ready and 'history' in locals():\n",
    "    # Example prediction on a validation image\n",
    "    print(\"Making a sample prediction...\")\n",
    "    \n",
    "    # Get a sample batch from validation data\n",
    "    for images, labels in val_ds.take(1):\n",
    "        sample_image = images[0]\n",
    "        true_label = np.argmax(labels[0])\n",
    "        \n",
    "        # Make prediction\n",
    "        prediction = model.predict(tf.expand_dims(sample_image, 0))\n",
    "        predicted_class = np.argmax(prediction[0])\n",
    "        confidence = prediction[0][predicted_class]\n",
    "        \n",
    "        # Display results\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.imshow(sample_image.numpy().astype('uint8'))\n",
    "        plt.axis('off')\n",
    "        plt.title(f\"True: {detector.class_names[true_label].replace('___', ' ')}\\n\"\n",
    "                 f\"Predicted: {detector.class_names[predicted_class].replace('___', ' ')}\\n\"\n",
    "                 f\"Confidence: {confidence:.3f}\")\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"True class: {detector.class_names[true_label]}\")\n",
    "        print(f\"Predicted class: {detector.class_names[predicted_class]}\")\n",
    "        print(f\"Confidence: {confidence:.4f}\")\n",
    "        \n",
    "        break\n",
    "        \n",
    "else:\n",
    "    print(\"üìù Example code for making predictions:\")\n",
    "    print(\"\"\"\n",
    "# Load a trained model\n",
    "detector = PlantDiseaseDetector()\n",
    "detector.load_model('models/plant_disease_model.h5')\n",
    "\n",
    "# Make prediction on a new image\n",
    "disease, confidence = detector.predict_disease('path/to/your/image.jpg')\n",
    "print(f\"Predicted Disease: {disease}\")\n",
    "print(f\"Confidence: {confidence:.2f}\")\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84422fa1",
   "metadata": {},
   "source": [
    "## üéØ Next Steps\n",
    "\n",
    "1. **Improve Model**: Experiment with different architectures, hyperparameters\n",
    "2. **Data Augmentation**: Try advanced augmentation techniques\n",
    "3. **Transfer Learning**: Use pre-trained models like ResNet, EfficientNet\n",
    "4. **Deployment**: Create a web app or mobile app for real-time detection\n",
    "5. **Extended Dataset**: Include more plant species and diseases\n",
    "\n",
    "## üìö Resources\n",
    "\n",
    "- [New Plant Diseases Dataset](https://www.kaggle.com/datasets/vipoooool/new-plant-diseases-dataset)\n",
    "- [TensorFlow Documentation](https://www.tensorflow.org/)\n",
    "- [Keras Applications](https://keras.io/api/applications/)\n",
    "- [Transfer Learning Guide](https://www.tensorflow.org/tutorials/images/transfer_learning)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
